{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce3da9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "# Add your project path if needed\n",
    "# sys.path.append('/path/to/your/project')\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ede5983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully imported NBEATSx components\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import the NBEATSx implementation\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # Adjust these imports based on your actual file structure\n",
    "    from nbeats import Nbeats\n",
    "    from nbeats_model import NBeats, NBeatsBlock, TrendBasis, SeasonalityBasis, IdentityBasis\n",
    "    print(\"✅ Successfully imported NBEATSx components\")\n",
    "except ImportError as e:\n",
    "    print(\"❌ Import error:\", e)\n",
    "    print(\"Please check your file paths and imports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef3df184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated synthetic data:\n",
      "X shape: (500, 60)\n",
      "y shape: (500, 12)\n",
      "X sample stats: mean=12.79, std=2.60\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Create synthetic time series data (mimicking your volatility targets)\n",
    "def create_synthetic_volatility_data(n_samples=1000, input_size=60, output_size=12):\n",
    "    \"\"\"\n",
    "    Create synthetic data that resembles your volatility targets\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create time series with trend + seasonality + noise (like VIX term structure)\n",
    "    time = np.arange(n_samples + input_size + output_size)\n",
    "    \n",
    "    # Base trend\n",
    "    trend = 0.01 * time + 10\n",
    "    \n",
    "    # Seasonal component (quarterly patterns in volatility)\n",
    "    seasonal = 3 * np.sin(2 * np.pi * time / 63)  # ~3 month cycle\n",
    "    \n",
    "    # Add volatility clustering (like real financial data)\n",
    "    noise = np.random.randn(len(time)) * 0.5\n",
    "    garch_vol = np.zeros(len(time))\n",
    "    garch_vol[0] = 1\n",
    "    for i in range(1, len(time)):\n",
    "        garch_vol[i] = 0.1 + 0.05 * noise[i-1]**2 + 0.9 * garch_vol[i-1]\n",
    "    \n",
    "    # Combine components\n",
    "    series = trend + seasonal + noise * garch_vol\n",
    "    \n",
    "    # Create input-output pairs\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        X.append(series[i:i+input_size])\n",
    "        y.append(series[i+input_size:i+input_size+output_size])\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Generate test data\n",
    "X_test, y_test = create_synthetic_volatility_data(n_samples=500, input_size=60, output_size=12)\n",
    "\n",
    "print(f\"Generated synthetic data:\")\n",
    "print(f\"X shape: {X_test.shape}\")  # Should be (500, 60)\n",
    "print(f\"y shape: {y_test.shape}\")  # Should be (500, 12)\n",
    "print(f\"X sample stats: mean={X_test.mean():.2f}, std={X_test.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a4b0b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created data loaders:\n",
      "Train samples: 400\n",
      "Val samples: 100\n",
      "Input size: 60\n",
      "Output size: 12\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Create a simple data loader class\n",
    "class SimpleTimeSeriesLoader:\n",
    "    \"\"\"\n",
    "    Simplified data loader that mimics the original TimeSeriesLoader interface\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.input_size = X.shape[1]\n",
    "        self.output_size = y.shape[1]\n",
    "        self.n_samples = len(X)\n",
    "        \n",
    "        # Create indices\n",
    "        self.indices = np.arange(self.n_samples)\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "        \n",
    "        self.current_idx = 0\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.current_idx = 0\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.current_idx >= self.n_samples:\n",
    "            raise StopIteration\n",
    "        \n",
    "        # Get batch indices\n",
    "        end_idx = min(self.current_idx + self.batch_size, self.n_samples)\n",
    "        batch_indices = self.indices[self.current_idx:end_idx]\n",
    "        \n",
    "        # Create batch\n",
    "        batch_X = self.X[batch_indices]\n",
    "        batch_y = self.y[batch_indices]\n",
    "        \n",
    "        # Create batch dictionary matching original interface\n",
    "        batch = {\n",
    "            'insample_y': batch_X,  # Historical data\n",
    "            'insample_x': np.zeros((len(batch_indices), 1, self.input_size)),  # Dummy exogenous\n",
    "            'insample_mask': np.ones((len(batch_indices), self.input_size)),  # No missing data\n",
    "            'outsample_x': np.zeros((len(batch_indices), 1, self.output_size)),  # Dummy exogenous\n",
    "            'outsample_y': batch_y,  # Target data\n",
    "            'outsample_mask': np.ones((len(batch_indices), self.output_size)),  # No missing data\n",
    "            's_matrix': np.zeros((len(batch_indices), 0))  # No static features\n",
    "        }\n",
    "        \n",
    "        self.current_idx = end_idx\n",
    "        return batch\n",
    "    \n",
    "    def get_n_variables(self):\n",
    "        # Return (n_temporal_exogenous, n_static_exogenous)\n",
    "        return 1, 0  # Simplified - just the target variable\n",
    "\n",
    "# Create data loaders\n",
    "train_size = int(0.8 * len(X_test))\n",
    "X_train, X_val = X_test[:train_size], X_test[train_size:]\n",
    "y_train, y_val = y_test[:train_size], y_test[train_size:]\n",
    "\n",
    "train_loader = SimpleTimeSeriesLoader(X_train, y_train, batch_size=32, shuffle=True)\n",
    "val_loader = SimpleTimeSeriesLoader(X_val, y_val, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Created data loaders:\")\n",
    "print(f\"Train samples: {len(X_train)}\")\n",
    "print(f\"Val samples: {len(X_val)}\")\n",
    "print(f\"Input size: {train_loader.input_size}\")\n",
    "print(f\"Output size: {train_loader.output_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca31ee0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully created NBEATSx model\n",
      "Model device: cpu\n",
      "Input size: 60\n",
      "Output size: 12\n",
      "Stack types: ['trend', 'seasonality', 'identity']\n",
      "N harmonics: 5\n",
      "N polynomials: 3\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Test NBEATSx model creation\n",
    "try:\n",
    "    # Create NBEATSx model with simplified configuration\n",
    "    # Fix: The original code expects single values for harmonics/polynomials per stack\n",
    "    model_config = {\n",
    "        'input_size_multiplier': 5,  # This means input_size = 5 * output_size = 60\n",
    "        'output_size': 12,  # Forecast horizon\n",
    "        'shared_weights': False,\n",
    "        'activation': 'relu',\n",
    "        'initialization': 'he_uniform',\n",
    "        'stack_types': ['trend', 'seasonality', 'identity'],\n",
    "        'n_blocks': [2, 2, 1],  # Number of blocks per stack\n",
    "        'n_layers': [4, 4, 4],  # Number of layers per stack\n",
    "        'n_hidden': [[256, 256, 256, 256], [256, 256, 256, 256], [256, 256, 256, 256]],  # Hidden units per layer\n",
    "        # Fix: These should be single values, not lists\n",
    "        'n_harmonics': 5,  # For seasonality stack (single value)\n",
    "        'n_polynomials': 3,  # For trend stack (single value)\n",
    "        'exogenous_n_channels': 0,  # No complex exogenous variables\n",
    "        'include_var_dict': None,  # Simplified\n",
    "        't_cols': None,  # Simplified\n",
    "        'batch_normalization': False,\n",
    "        'dropout_prob_theta': 0.1,\n",
    "        'dropout_prob_exogenous': 0.1,\n",
    "        'x_s_n_hidden': 0,  # No static features\n",
    "        'learning_rate': 0.001,\n",
    "        'lr_decay': 0.5,\n",
    "        'n_lr_decay_steps': 3,\n",
    "        'weight_decay': 1e-4,\n",
    "        'l1_theta': 0.0,\n",
    "        'n_iterations': 100,  # Just for quick test\n",
    "        'early_stopping': 10,\n",
    "        'loss': 'MAE',\n",
    "        'loss_hypar': None,\n",
    "        'val_loss': 'MAE',\n",
    "        'random_seed': 42,\n",
    "        'seasonality': 7,  # Daily seasonality\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    }\n",
    "    \n",
    "    # Create model\n",
    "    nbeats_model = Nbeats(**model_config)\n",
    "    \n",
    "    print(\"✅ Successfully created NBEATSx model\")\n",
    "    print(f\"Model device: {nbeats_model.device}\")\n",
    "    print(f\"Input size: {nbeats_model.input_size}\")\n",
    "    print(f\"Output size: {nbeats_model.output_size}\")\n",
    "    print(f\"Stack types: {nbeats_model.stack_types}\")\n",
    "    print(f\"N harmonics: {nbeats_model.n_harmonics}\")\n",
    "    print(f\"N polynomials: {nbeats_model.n_polynomials}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"❌ Error creating model:\", e)\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46768db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training test...\n",
      "❌ Error during training: module 'numpy' has no attribute 'float'.\n",
      "`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/31/b1v52j156gbfz83pmrnth3jc0000gn/T/ipykernel_121/2736211935.py\", line 6, in <module>\n",
      "    nbeats_model.fit(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        train_ts_loader=train_loader,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        eval_steps=10\n",
      "        ^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/jamesliu/Documents/GitHub/bloomberg-metalearning/models/base/nbeatsx/nbeats.py\", line 410, in fit\n",
      "    block_list = self.create_stack()\n",
      "  File \"/Users/jamesliu/Documents/GitHub/bloomberg-metalearning/models/base/nbeatsx/nbeats.py\", line 262, in create_stack\n",
      "    basis=TrendBasis(degree_of_polynomial=self.n_polynomials,\n",
      "          ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                             backcast_size=self.input_size,\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                             forecast_size=self.output_size),\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jamesliu/Documents/GitHub/bloomberg-metalearning/models/base/nbeatsx/nbeats_model.py\", line 192, in __init__\n",
      "    t.tensor(np.concatenate([np.power(np.arange(backcast_size, dtype=np.float) / backcast_size, i)[None, :]\n",
      "                                                                     ^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/finance/lib/python3.13/site-packages/numpy/__init__.py\", line 397, in __getattr__\n",
      "    raise AttributeError(__former_attrs__[attr], name=None)\n",
      "AttributeError: module 'numpy' has no attribute 'float'.\n",
      "`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Test model training (quick test)\n",
    "try:\n",
    "    print(\"Starting model training test...\")\n",
    "    \n",
    "    # Train for just a few iterations to test\n",
    "    nbeats_model.fit(\n",
    "        train_ts_loader=train_loader,\n",
    "        val_ts_loader=val_loader,\n",
    "        n_iterations=50,  # Very short for quick test\n",
    "        verbose=True,\n",
    "        eval_steps=10\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Training test completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"❌ Error during training:\", e)\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5cb87d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
